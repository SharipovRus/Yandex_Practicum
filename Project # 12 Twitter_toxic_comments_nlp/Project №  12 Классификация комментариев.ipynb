{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412ad848",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f75a51",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества F1 не меньше 0.75.\n",
    "\n",
    "План по выполнению проекта\n",
    "\n",
    "1. Загрузим и подготовим данные.\n",
    "2. Обучим разные модели.\n",
    "3. Сделаем выводы.\n",
    "\n",
    "\n",
    "Описание данных\n",
    "\n",
    "Данные находятся в файле toxic_comments.csv. Столбец text в нём содержит текст комментария, а toxic — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a716f0",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e98f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\79811\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b516db9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\79811\\anaconda3\\lib\\site-packages (4.19.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\79811\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ca9239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\79811\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\79811\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install  torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14baea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in c:\\users\\79811\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\79811\\anaconda3\\lib\\site-packages (from pymystem3) (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->pymystem3) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->pymystem3) (1.26.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb02ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\79811\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\79811\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: wheel in c:\\users\\79811\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\79811\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f36389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier \n",
    "from pymystem3 import Mystem\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1609fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('C:/Users/79811/Downloads/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8491a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115207dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0.0\n",
       "toxic    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3daa2352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>159571</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text          toxic\n",
       "count                                              159571  159571.000000\n",
       "unique                                             159571            NaN\n",
       "top     Explanation\\nWhy the edits made under my usern...            NaN\n",
       "freq                                                    1            NaN\n",
       "mean                                                  NaN       0.101679\n",
       "std                                                   NaN       0.302226\n",
       "min                                                   NaN       0.000000\n",
       "25%                                                   NaN       0.000000\n",
       "50%                                                   NaN       0.000000\n",
       "75%                                                   NaN       0.000000\n",
       "max                                                   NaN       1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24c7c259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d599898a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e907e2",
   "metadata": {},
   "source": [
    "**ВЫВОДЫ ПО ДАННЫМ** \n",
    "\n",
    "- 159 571 строк\n",
    "- Пропусков и дубликатов не замечено \n",
    "- только 10% твитов являются токсичными\n",
    "- в столбце text содержатся тексты  твиты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6a22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6c06fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['text'] = data['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370407ee",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e99dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = data.drop('toxic', axis = 1)\n",
    "te = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12d6157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_train, tr_test, te_train, te_test = train_test_split(tr, te, test_size = 0.3, random_state = 12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1603f8",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcb16f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10, 'clf__class_weight': 'balanced'}\n",
      "0.7737116850856252\n",
      "Wall time: 6min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "log_reg = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LogisticRegression(random_state=12345))])\n",
    "\n",
    "params = {'clf__C': [0.1, 1, 10, 100],\n",
    "          'clf__class_weight': ['balanced', None]}\n",
    "\n",
    "log_reg_grid = GridSearchCV(estimator=log_reg, param_grid=params, cv=3, scoring='f1', n_jobs=-1, refit=False)\n",
    "log_reg_grid.fit(tr_train['text'], te_train)\n",
    "log_reg_params_best = log_reg_grid.best_params_\n",
    "\n",
    "print(log_reg_params_best)\n",
    "print(log_reg_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f9b63",
   "metadata": {},
   "source": [
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "839671f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__learning_rate': 0.25, 'clf__max_depth': -1, 'clf__n_estimators': 200}\n",
      "0.7675168724246589\n",
      "Wall time: 13min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_ = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)),\n",
    "    ('clf', LGBMClassifier(random_state=12345))])\n",
    "\n",
    "params = {\n",
    "  'clf__n_estimators': [200],\n",
    "  'clf__learning_rate': [0.15, 0.25],\n",
    "  'clf__max_depth': [8, 10, -1]}\n",
    "\n",
    "lgbm_grid = GridSearchCV(estimator=lgbm_, param_grid=params, cv=3, scoring='f1', n_jobs=-1, refit=False)\n",
    "lgbm_grid.fit(tr_train['text'],te_train)\n",
    "lgbm_params_best = lgbm_grid.best_params_\n",
    "\n",
    "print(lgbm_params_best)\n",
    "print(lgbm_grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a4c202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(ngram_range=(1,3),\n",
    "               min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a08107c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_train = vectorize.fit_transform(tr_train['text'])\n",
    "tr_test = vectorize.transform(tr_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad281590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', random_state=12345)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_mod = LogisticRegression(C=10, class_weight='balanced', random_state=12345)\n",
    "log_reg_mod.fit(tr_train, te_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b861013d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.25, n_estimators=200, random_state=12345)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_mod = LGBMClassifier(learning_rate=0.25, max_depth=-1, n_estimators=200, random_state = 12345)\n",
    "lgbm_mod.fit(tr_train, te_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e9803ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(fitted_model):\n",
    "    test_pred = fitted_model.predict(tr_test)\n",
    "    test_f1 = f1_score(te_test, test_pred)\n",
    "    \n",
    "    print('F1 on test: {:.3f}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8450e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on test: 0.783\n"
     ]
    }
   ],
   "source": [
    "get_f1(log_reg_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da48ea96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 on test: 0.777\n"
     ]
    }
   ],
   "source": [
    "get_f1(lgbm_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa62165",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69b331ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_pretrained_bert in c:\\users\\79811\\anaconda3\\lib\\site-packages (0.6.2)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: boto3 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (1.23.10)\n",
      "Requirement already satisfied: requests in c:\\users\\79811\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (2.26.0)\n",
      "Requirement already satisfied: regex in c:\\users\\79811\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (2021.8.3)\n",
      "Requirement already satisfied: torch>=0.4.1 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (1.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\79811\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (1.20.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\79811\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\79811\\anaconda3\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n",
      "Requirement already satisfied: botocore<1.27.0,>=1.26.10 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from boto3->pytorch_pretrained_bert) (1.26.10)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from boto3->pytorch_pretrained_bert) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from boto3->pytorch_pretrained_bert) (0.5.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from botocore<1.27.0,>=1.26.10->boto3->pytorch_pretrained_bert) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from botocore<1.27.0,>=1.26.10->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.10->boto3->pytorch_pretrained_bert) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->pytorch_pretrained_bert) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\79811\\anaconda3\\lib\\site-packages (from requests->pytorch_pretrained_bert) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\79811\\anaconda3\\lib\\site-packages (from tqdm->pytorch_pretrained_bert) (0.4.4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d50f9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2632eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62d204d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('C:/Users/79811/Downloads/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.head(10)\n",
    "df = df.sample(500, random_state = 12345).reset_index(drop=True)\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True, do_basic_tokenize=True)\n",
    "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85c3ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['text'].apply((lambda x: tokenizer.encode(x, #текст\n",
    "                                                         add_special_tokens=True, #особые токены начала и конца текста\n",
    "                                                         truncation=True)) #усечение до числа входов модели\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f44185cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.map(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c8bab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a5c88c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183424201d96436db9dd9a3980c8554c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8abcd04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['toxic']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "471a52f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c07d8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea18d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=12345) #тут немного переиграем, для подбора порога используем\n",
    "#отдельную выборку, валидационную\n",
    "features_test, features_valid, target_test, target_valid = train_test_split(features_test, target_test, test_size=0.5, random_state=12345)\n",
    "def score(model):\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_test)\n",
    "    f1 = f1_score(target_test, predictions)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cf61968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4615384615384615\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', random_state=12345)\n",
    "print(score(model))\n",
    "model=LGBMClassifier(class_weight='balanced', random_state=12345)\n",
    "print(score(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d7e7a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   23.5s remaining:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   26.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV #\n",
    "c_values = np.logspace(-2, 3, 500) #значения C для перебора\n",
    "model = LogisticRegressionCV(Cs=c_values, verbose=1, n_jobs=-1, penalty='l1', scoring='f1', class_weight='balanced', solver='liblinear').fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c1fd24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17073170731707318 0.0\n",
      "0.6666666666666665 0.01\n",
      "0.6250000000000001 0.02\n",
      "0.6666666666666666 0.03\n",
      "0.7142857142857143 0.04\n",
      "0.7142857142857143 0.05\n",
      "0.7142857142857143 0.06\n",
      "0.7142857142857143 0.07\n",
      "0.7142857142857143 0.08\n",
      "0.7142857142857143 0.09\n",
      "0.7142857142857143 0.1\n",
      "0.7142857142857143 0.11\n",
      "0.7142857142857143 0.12\n",
      "0.7142857142857143 0.13\n",
      "0.7142857142857143 0.14\n",
      "0.7142857142857143 0.15\n",
      "0.7142857142857143 0.16\n",
      "0.7142857142857143 0.17\n",
      "0.7142857142857143 0.18\n",
      "0.7142857142857143 0.19\n",
      "0.7142857142857143 0.2\n",
      "0.7142857142857143 0.21\n",
      "0.7142857142857143 0.22\n",
      "0.7142857142857143 0.23\n",
      "0.7142857142857143 0.24\n",
      "0.7142857142857143 0.25\n",
      "0.7142857142857143 0.26\n",
      "0.7142857142857143 0.27\n",
      "0.7142857142857143 0.28\n",
      "0.7142857142857143 0.29\n",
      "0.7142857142857143 0.3\n",
      "0.7142857142857143 0.31\n",
      "0.7142857142857143 0.32\n",
      "0.7142857142857143 0.33\n",
      "0.7142857142857143 0.34\n",
      "0.7142857142857143 0.35000000000000003\n",
      "0.7142857142857143 0.36\n",
      "0.6153846153846153 0.37\n",
      "0.6153846153846153 0.38\n",
      "0.6153846153846153 0.39\n",
      "0.6153846153846153 0.4\n",
      "0.6153846153846153 0.41000000000000003\n",
      "0.6153846153846153 0.42\n",
      "0.6153846153846153 0.43\n",
      "0.6153846153846153 0.44\n",
      "0.6153846153846153 0.45\n",
      "0.6153846153846153 0.46\n",
      "0.6153846153846153 0.47000000000000003\n",
      "0.6153846153846153 0.48\n",
      "0.6153846153846153 0.49\n",
      "0.6153846153846153 0.5\n",
      "0.6153846153846153 0.51\n",
      "0.6153846153846153 0.52\n",
      "0.6153846153846153 0.53\n",
      "0.6153846153846153 0.54\n",
      "0.6153846153846153 0.55\n",
      "0.6153846153846153 0.56\n",
      "0.6153846153846153 0.5700000000000001\n",
      "0.6153846153846153 0.58\n",
      "0.6153846153846153 0.59\n",
      "0.6153846153846153 0.6\n",
      "0.6153846153846153 0.61\n",
      "0.6153846153846153 0.62\n",
      "0.6153846153846153 0.63\n",
      "0.6153846153846153 0.64\n",
      "0.6153846153846153 0.65\n",
      "0.6153846153846153 0.66\n",
      "0.6153846153846153 0.67\n",
      "0.6153846153846153 0.68\n",
      "0.6153846153846153 0.6900000000000001\n",
      "0.6153846153846153 0.7000000000000001\n",
      "0.6153846153846153 0.71\n",
      "0.6153846153846153 0.72\n",
      "0.6153846153846153 0.73\n",
      "0.6153846153846153 0.74\n",
      "0.6153846153846153 0.75\n",
      "0.6153846153846153 0.76\n",
      "0.6153846153846153 0.77\n",
      "0.6153846153846153 0.78\n",
      "0.6153846153846153 0.79\n",
      "0.6153846153846153 0.8\n",
      "0.6153846153846153 0.81\n",
      "0.6153846153846153 0.8200000000000001\n",
      "0.6153846153846153 0.8300000000000001\n",
      "0.6153846153846153 0.84\n",
      "0.6153846153846153 0.85\n",
      "0.6153846153846153 0.86\n",
      "0.6153846153846153 0.87\n",
      "0.6153846153846153 0.88\n",
      "0.6153846153846153 0.89\n",
      "0.6153846153846153 0.9\n",
      "0.6153846153846153 0.91\n",
      "0.6666666666666666 0.92\n",
      "0.6666666666666666 0.93\n",
      "0.6666666666666666 0.9400000000000001\n",
      "0.6666666666666666 0.9500000000000001\n",
      "0.6666666666666666 0.96\n",
      "0.6666666666666666 0.97\n",
      "0.6666666666666666 0.98\n",
      "0.7272727272727273 0.99\n"
     ]
    }
   ],
   "source": [
    "best_tr = None #лучшего порога для логистической регрессии сначала нет, как будем находить лучший вариант, будем его сюда перезаписывать\n",
    "best_f1 = 0 #примем лучшее значение f1 изначально за самый плохой вариант, по мере того, как будем находить лучший вариант, будем перезаписывать\n",
    "for tr in (np.array(range(0, 100)) * 0.01): #теперь для настроенной версии перебираем порог\n",
    "    print(\n",
    "        f1_score((model.predict_proba(features_valid)[:,1] > tr) * 1.0, target_valid), #f1 с текщим порогом, заметь, что проверяем на валидационной выборке\n",
    "         tr #сам порог\n",
    "          )\n",
    "    if f1_score((model.predict_proba(features_valid)[:,1] > tr) * 1.0, target_valid) > best_f1: #если текущее f1 лучше того, который сейчас записан как лучший\n",
    "        best_f1 = f1_score((model.predict_proba(features_valid)[:,1] > tr) * 1.0, target_valid) #перезапишем лучшее f1 текущим значением\n",
    "        best_tr = tr #и возьмём текущий порог как лучший"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cde0653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "print(f1_score((model.predict_proba(features_valid)[:,1] > best_tr) * 1.0, target_valid)) #ещё раз смотрим f1 на валидации, выглядит не достаточно хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5daa6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   25.9s remaining:   38.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   33.3s finished\n"
     ]
    }
   ],
   "source": [
    "print(f1_score( #f1 на тесте\n",
    "    (model.fit(np.concatenate((features_train, features_valid)), np.concatenate((target_train.values, target_valid.values))).predict_proba(features_test)[:,1] > best_tr) * 1.0,\n",
    "    #обучим модель на объединенной валидационной выборке и обучающей, не пропадать же данным, чем больше данных, тем качественнее можно получить предсказание в общем случае\n",
    "    #и получим для неё предсказания с учётом найденного ранее порога\n",
    "     target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864a375",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d2c8923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BERT_LogisticRegression</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BERT_LGBMRegressor</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model     F1\n",
       "0            LGBMRegressor  0.777\n",
       "1       LogisticRegression  0.783\n",
       "2  BERT_LogisticRegression  0.425\n",
       "3       BERT_LGBMRegressor  0.250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {\n",
    "    'Model' : ['LGBMRegressor', 'LogisticRegression', 'BERT_LogisticRegression', 'BERT_LGBMRegressor'],\n",
    "    'F1' :pd.Series([0.777,  0.783, 0.425, 0.25]),\n",
    "    }\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cffb24",
   "metadata": {},
   "source": [
    "В общем лучший результат у меня получился на LogisticRegression. Я так же попытался с бертом побороться, но вышел не очень удовльтворительный результат. Сначала у меня выдавало 0.678 результат для LogisticRegression, а теперь 0.425. \n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 46,
    "start_time": "2022-06-09T20:10:50.317Z"
   },
   {
    "duration": 2073,
    "start_time": "2022-07-11T13:50:22.118Z"
   },
   {
    "duration": 2327,
    "start_time": "2022-07-11T13:50:24.193Z"
   },
   {
    "duration": 1961,
    "start_time": "2022-07-11T13:50:26.521Z"
   },
   {
    "duration": 2031,
    "start_time": "2022-07-11T13:50:28.485Z"
   },
   {
    "duration": 2079,
    "start_time": "2022-07-11T13:50:30.518Z"
   },
   {
    "duration": 91124,
    "start_time": "2022-07-11T13:50:32.599Z"
   },
   {
    "duration": 3164,
    "start_time": "2022-07-11T13:52:03.724Z"
   },
   {
    "duration": 32,
    "start_time": "2022-07-11T13:52:06.890Z"
   },
   {
    "duration": 28,
    "start_time": "2022-07-11T13:52:06.924Z"
   },
   {
    "duration": 259,
    "start_time": "2022-07-11T13:52:06.956Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-11T13:52:07.217Z"
   },
   {
    "duration": 233,
    "start_time": "2022-07-11T13:52:07.225Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-11T13:52:07.460Z"
   },
   {
    "duration": 8129,
    "start_time": "2022-07-11T13:52:07.467Z"
   },
   {
    "duration": 13,
    "start_time": "2022-07-11T13:52:15.598Z"
   },
   {
    "duration": 40,
    "start_time": "2022-07-11T13:52:15.613Z"
   },
   {
    "duration": 1186754,
    "start_time": "2022-07-11T13:52:15.655Z"
   }
  ],
  "celltoolbar": "Необработанный формат ячейки",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
